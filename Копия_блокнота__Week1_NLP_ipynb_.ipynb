{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVvNRcmhJIym",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ad9e39df335bc0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sentiment analysis of movie reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxfkORWJJPHL",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c84206e9e535261",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SdgybQj8JIyp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e5d7a9b38b30dbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c5ccf034-1e43-437d-ba52-098a036d5892"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('https://github.com/mbburova/MDS/raw/main/sentiment.csv', index_col = 0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CGHmoXeJIys",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-403136218c67f499",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 1 (1 points)**\n",
    "It seems that data contains some unnecessary HTML tags such as `<br />`, for example.\n",
    "\n",
    "Find all types of HTML tags (the types of expressions in brackets of the form `<...>`). \n",
    "\n",
    "\n",
    "How many different tag types are their in the data? What is the most frequent tag? \n",
    "\n",
    "Write your answer as a string separating tag_count and most popular tag by space. \n",
    "\n",
    "**Example answer:** `\"3 <p>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSVRfDg4JIys",
    "outputId": "a5904e8b-a641-4057-9dc6-c42b270c6454",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'br /': 40968, 'SPOILER': 1, '/SPOILER': 1})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "### YOUR SOLUTION\n",
    "pattern=re.compile('<(.+?)>')\n",
    "lines = []\n",
    "for index, row in data.iterrows():\n",
    "    line = re.findall(pattern, row['review'])\n",
    "    lines = lines + line\n",
    "\n",
    "cnt = Counter()\n",
    "for word in lines:\n",
    "    cnt[word] += 1\n",
    "cnt\n",
    "print(cnt)\n",
    "q1 = \"formatted string with tag count and the most popular tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Ck8P3u9Ofv_5"
   },
   "outputs": [],
   "source": [
    "#ans: \"3 <br />\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKbtlmLeJIyu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aff35c049fb42a5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 2 (1 points)**\n",
    "\n",
    "Prepare your text. For this, replace tags from task 1 by spaces, remove multiple spaces (which may appear after tag removal), relace back slashes (`\\`) with zero string,  and lower the text and strip it using `text.strip()`.\n",
    "\n",
    "What is the mean number of unique characters in the review? \n",
    "\n",
    "Calculate number of unique characters in a string using `len(set(string))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "TT15PjTsJIyu"
   },
   "outputs": [],
   "source": [
    "# data['cleaned_reaview'] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "8agBBgAVtI8-"
   },
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "  new_txt = re.sub('<(.+?)>', '', text)\n",
    "  txt = \" \".join(new_txt.split()).replace('\\\\', '').lower()\n",
    "  return(txt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PAFaUMvqHWJr",
    "outputId": "8dcfe70a-be06-4d3a-c31b-7f254ede0d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do not like \"titanic\"'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_prepare('Do not like \\\"Titanic\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RzMuZjqxR6Os",
    "outputId": "6b42550d-964f-4a9f-c785-01975628cff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic tests are passed.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_text_prepare():\n",
    "    examples = ['Best film I have ever seen <SMILE::>',\n",
    "                'Do not like \\\"Titanic\\\"',\n",
    "                'Can say just    .... Nothing!!! <SAD>']\n",
    "    answers = ['best film i have ever seen',\n",
    "                'do not like \"titanic\"',\n",
    "                'can say just .... nothing!!!']\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if text_prepare(ex) != ans:\n",
    "            print(text_prepare(ex))\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'\n",
    "test_text_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "mt1o4oGoJPHV"
   },
   "outputs": [],
   "source": [
    "# q2 =### YOUR SOLUTION\n",
    "\n",
    "data['cleaned_review'] = data['review'].apply(text_prepare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "G2kLeJiLJqgz"
   },
   "outputs": [],
   "source": [
    "data['unique'] = data['cleaned_review'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylxjhTgkKEnR",
    "outputId": "a44a9150-916e-4e51-f5e5-052def392c37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.7798"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unique.mean()\n",
    "#ans: 33.7798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bwmnkQUQKzZz",
    "outputId": "18ef0dd0-bcb2-4911-c1f3-e34989840e71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds\" by timothy hine...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager (nicholas bell)...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>I actually saw this movie at a theater. As soo...</td>\n",
       "      <td>i actually saw this movie at a theater. as soo...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't quite get the rating for The Amati Gir...</td>\n",
       "      <td>i don't quite get the rating for the amati gir...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>*Contains some spoilers* This movie is cheesy ...</td>\n",
       "      <td>*contains some spoilers* this movie is cheesy ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm, Hip Hop music to a period western. Modern...</td>\n",
       "      <td>hmm, hip hop music to a period western. modern...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>clark gable plays a con man who busts into the...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review  \\\n",
       "0             1  With all this stuff going down at the moment w...   \n",
       "1             1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2             0  The film starts with a manager (Nicholas Bell)...   \n",
       "3             0  It must be assumed that those who praised this...   \n",
       "4             1  Superbly trashy and wondrously unpretentious 8...   \n",
       "...         ...                                                ...   \n",
       "9995          0  I actually saw this movie at a theater. As soo...   \n",
       "9996          0  I don't quite get the rating for The Amati Gir...   \n",
       "9997          0  *Contains some spoilers* This movie is cheesy ...   \n",
       "9998          0  Hmm, Hip Hop music to a period western. Modern...   \n",
       "9999          1  Clark Gable plays a con man who busts into the...   \n",
       "\n",
       "                                         cleaned_review  unique  \n",
       "0     with all this stuff going down at the moment w...      36  \n",
       "1     the classic war of the worlds\" by timothy hine...      29  \n",
       "2     the film starts with a manager (nicholas bell)...      39  \n",
       "3     it must be assumed that those who praised this...      39  \n",
       "4     superbly trashy and wondrously unpretentious 8...      41  \n",
       "...                                                 ...     ...  \n",
       "9995  i actually saw this movie at a theater. as soo...      31  \n",
       "9996  i don't quite get the rating for the amati gir...      36  \n",
       "9997  *contains some spoilers* this movie is cheesy ...      39  \n",
       "9998  hmm, hip hop music to a period western. modern...      30  \n",
       "9999  clark gable plays a con man who busts into the...      33  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AY3zfS5JIyx"
   },
   "source": [
    "**Task 3 (1 point)**\n",
    "\n",
    "For sentiment analysis brackets may serve as a useful feature. Create feature counters for the number of positive smiles (opening brackets `)`) and for the negative smiles (opening brackets `(`) in the reviews. In the answer write a sum of their averages (`mean_positive + mean_negative`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "qbtlYDtpJIyx"
   },
   "outputs": [],
   "source": [
    "data['positive_count'] = data['cleaned_review'].apply(lambda x: x.count(')'))\n",
    "data['negative_count'] = data['cleaned_review'].apply(lambda x: x.count('('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3EN_9OIJPHX",
    "outputId": "3e2c5179-1d6e-4256-c7c4-a832118e5bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9163"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q3 =  ### YOUR SOLUTION\n",
    "\n",
    "data.positive_count.mean() + data.negative_count.mean()\n",
    "\n",
    "#ans: 2.9163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBzh5Tw6JIyy"
   },
   "source": [
    "**Task 4 (1 point)**\n",
    "Now remove all characters which are not English letters (`[a-zA-z]`) or digits (`[0-9]`) and tokenize the text splitting it by spaces. \n",
    "\n",
    "**Example:**\n",
    "`'mother+father = parents'` -> `[mother, father, parents]`\n",
    "\n",
    "Then remove stop words using nltk stopwords list for English (see cell below).\n",
    "\n",
    "What is the mean number of unique tokens in a review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "uXAyRKMqJPHY"
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2Mkk0XjJIyz",
    "outputId": "e8a523f8-9a73-4a0a-e52a-f33d49d93d06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/riya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "WW8ovBWMJIyz"
   },
   "outputs": [],
   "source": [
    "# data['tokenized'] = ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "ZYJPqRXhJIy0"
   },
   "outputs": [],
   "source": [
    "def remove_characters(text):\n",
    "  new_txt = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
    "  txt = \" \".join(new_txt.split()).split()\n",
    "  # txt = \" \".join(new_txt.split())\n",
    "  return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9bYdmBCcouD",
    "outputId": "b37c38b9-c15a-4bbd-dc7f-c0c30973c47f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains', 'some', 'spoilers', 'this', 'movie', 'is', 'cheesy']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_characters('*contains some spoilers* this movie is cheesy ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "yAVj4m20ZJY8"
   },
   "outputs": [],
   "source": [
    "data['tokenized'] = data['cleaned_review'].apply(remove_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "McnKISK4bLi0",
    "outputId": "3406011e-d5f0-4273-806d-b008463b8f89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>unique</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[with, all, this, stuff, going, down, at, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds\" by timothy hine...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[the, classic, war, of, the, worlds, by, timot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager (nicholas bell)...</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[the, film, starts, with, a, manager, nicholas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[it, must, be, assumed, that, those, who, prai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[superbly, trashy, and, wondrously, unpretenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>I actually saw this movie at a theater. As soo...</td>\n",
       "      <td>i actually saw this movie at a theater. as soo...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, actually, saw, this, movie, at, a, theater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't quite get the rating for The Amati Gir...</td>\n",
       "      <td>i don't quite get the rating for the amati gir...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, don, t, quite, get, the, rating, for, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>*Contains some spoilers* This movie is cheesy ...</td>\n",
       "      <td>*contains some spoilers* this movie is cheesy ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[contains, some, spoilers, this, movie, is, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm, Hip Hop music to a period western. Modern...</td>\n",
       "      <td>hmm, hip hop music to a period western. modern...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hmm, hip, hop, music, to, a, period, western,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>clark gable plays a con man who busts into the...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[clark, gable, plays, a, con, man, who, busts,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review  \\\n",
       "0             1  With all this stuff going down at the moment w...   \n",
       "1             1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2             0  The film starts with a manager (Nicholas Bell)...   \n",
       "3             0  It must be assumed that those who praised this...   \n",
       "4             1  Superbly trashy and wondrously unpretentious 8...   \n",
       "...         ...                                                ...   \n",
       "9995          0  I actually saw this movie at a theater. As soo...   \n",
       "9996          0  I don't quite get the rating for The Amati Gir...   \n",
       "9997          0  *Contains some spoilers* This movie is cheesy ...   \n",
       "9998          0  Hmm, Hip Hop music to a period western. Modern...   \n",
       "9999          1  Clark Gable plays a con man who busts into the...   \n",
       "\n",
       "                                         cleaned_review  unique  \\\n",
       "0     with all this stuff going down at the moment w...      36   \n",
       "1     the classic war of the worlds\" by timothy hine...      29   \n",
       "2     the film starts with a manager (nicholas bell)...      39   \n",
       "3     it must be assumed that those who praised this...      39   \n",
       "4     superbly trashy and wondrously unpretentious 8...      41   \n",
       "...                                                 ...     ...   \n",
       "9995  i actually saw this movie at a theater. as soo...      31   \n",
       "9996  i don't quite get the rating for the amati gir...      36   \n",
       "9997  *contains some spoilers* this movie is cheesy ...      39   \n",
       "9998  hmm, hip hop music to a period western. modern...      30   \n",
       "9999  clark gable plays a con man who busts into the...      33   \n",
       "\n",
       "      positive_count  negative_count  \\\n",
       "0                  1               1   \n",
       "1                  0               0   \n",
       "2                  8               8   \n",
       "3                  3               3   \n",
       "4                  1               1   \n",
       "...              ...             ...   \n",
       "9995               0               0   \n",
       "9996               0               0   \n",
       "9997               0               0   \n",
       "9998               0               0   \n",
       "9999               1               1   \n",
       "\n",
       "                                              tokenized  \n",
       "0     [with, all, this, stuff, going, down, at, the,...  \n",
       "1     [the, classic, war, of, the, worlds, by, timot...  \n",
       "2     [the, film, starts, with, a, manager, nicholas...  \n",
       "3     [it, must, be, assumed, that, those, who, prai...  \n",
       "4     [superbly, trashy, and, wondrously, unpretenti...  \n",
       "...                                                 ...  \n",
       "9995  [i, actually, saw, this, movie, at, a, theater...  \n",
       "9996  [i, don, t, quite, get, the, rating, for, the,...  \n",
       "9997  [contains, some, spoilers, this, movie, is, ch...  \n",
       "9998  [hmm, hip, hop, music, to, a, period, western,...  \n",
       "9999  [clark, gable, plays, a, con, man, who, busts,...  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "CFCPJMWcZmV2"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(words):\n",
    "  for word in list(words):\n",
    "    if word in STOPWORDS:\n",
    "      words.remove(word)\n",
    "  return(words)\n",
    "data['tokenized'] = data['tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgrC07JlbrxP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "icEyrDIxa6Is"
   },
   "outputs": [],
   "source": [
    "\n",
    "data['tokens_num'] = data['tokenized'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHDTvYy_buyk",
    "outputId": "e16251c1-0908-4f3e-f8eb-3283f0c2fbc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0712"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens_num'].mean()\n",
    "\n",
    "#ans: 100.0712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N08b-5jkJIy1"
   },
   "source": [
    "**Task 5 (1 point)**\n",
    "\n",
    "Using the same preprocessing as in task 4, tokenize the text into 3-grams. \n",
    "\n",
    "What is the most common 3-gram?\n",
    "\n",
    "**Example answer:** `\"the cat sat\"`.\n",
    "\n",
    "**Hint:** You may use `data['tokenized']` column and function `ngrams` from `nltk.util`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "zkp25EYgJIy1"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "data['ngrams'] = data['tokenized'].apply(lambda x: list(ngrams(x, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hZqsebqOJIy2",
    "outputId": "71a8cdae-d28c-452f-8ecc-c876b7252446"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>unique</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokens_num</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "      <td>167</td>\n",
       "      <td>[(stuff, going, moment), (going, moment, mj), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds\" by timothy hine...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[classic, war, worlds, timothy, hines, enterta...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(classic, war, worlds), (war, worlds, timothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager (nicholas bell)...</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[film, starts, manager, nicholas, bell, giving...</td>\n",
       "      <td>217</td>\n",
       "      <td>[(film, starts, manager), (starts, manager, ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[must, assumed, praised, film, greatest, filme...</td>\n",
       "      <td>164</td>\n",
       "      <td>[(must, assumed, praised), (assumed, praised, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "      <td>194</td>\n",
       "      <td>[(superbly, trashy, wondrously), (trashy, wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>I actually saw this movie at a theater. As soo...</td>\n",
       "      <td>i actually saw this movie at a theater. as soo...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[actually, saw, movie, theater, soon, handed, ...</td>\n",
       "      <td>45</td>\n",
       "      <td>[(actually, saw, movie), (saw, movie, theater)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't quite get the rating for The Amati Gir...</td>\n",
       "      <td>i don't quite get the rating for the amati gir...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[quite, get, rating, amati, girls, think, real...</td>\n",
       "      <td>72</td>\n",
       "      <td>[(quite, get, rating), (get, rating, amati), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>*Contains some spoilers* This movie is cheesy ...</td>\n",
       "      <td>*contains some spoilers* this movie is cheesy ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[contains, spoilers, movie, cheesy, 80s, horro...</td>\n",
       "      <td>206</td>\n",
       "      <td>[(contains, spoilers, movie), (spoilers, movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm, Hip Hop music to a period western. Modern...</td>\n",
       "      <td>hmm, hip hop music to a period western. modern...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hmm, hip, hop, music, period, western, modern...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(hmm, hip, hop), (hip, hop, music), (hop, mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>clark gable plays a con man who busts into the...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[clark, gable, plays, con, man, busts, life, h...</td>\n",
       "      <td>91</td>\n",
       "      <td>[(clark, gable, plays), (gable, plays, con), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review  \\\n",
       "0             1  With all this stuff going down at the moment w...   \n",
       "1             1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2             0  The film starts with a manager (Nicholas Bell)...   \n",
       "3             0  It must be assumed that those who praised this...   \n",
       "4             1  Superbly trashy and wondrously unpretentious 8...   \n",
       "...         ...                                                ...   \n",
       "9995          0  I actually saw this movie at a theater. As soo...   \n",
       "9996          0  I don't quite get the rating for The Amati Gir...   \n",
       "9997          0  *Contains some spoilers* This movie is cheesy ...   \n",
       "9998          0  Hmm, Hip Hop music to a period western. Modern...   \n",
       "9999          1  Clark Gable plays a con man who busts into the...   \n",
       "\n",
       "                                         cleaned_review  unique  \\\n",
       "0     with all this stuff going down at the moment w...      36   \n",
       "1     the classic war of the worlds\" by timothy hine...      29   \n",
       "2     the film starts with a manager (nicholas bell)...      39   \n",
       "3     it must be assumed that those who praised this...      39   \n",
       "4     superbly trashy and wondrously unpretentious 8...      41   \n",
       "...                                                 ...     ...   \n",
       "9995  i actually saw this movie at a theater. as soo...      31   \n",
       "9996  i don't quite get the rating for the amati gir...      36   \n",
       "9997  *contains some spoilers* this movie is cheesy ...      39   \n",
       "9998  hmm, hip hop music to a period western. modern...      30   \n",
       "9999  clark gable plays a con man who busts into the...      33   \n",
       "\n",
       "      positive_count  negative_count  \\\n",
       "0                  1               1   \n",
       "1                  0               0   \n",
       "2                  8               8   \n",
       "3                  3               3   \n",
       "4                  1               1   \n",
       "...              ...             ...   \n",
       "9995               0               0   \n",
       "9996               0               0   \n",
       "9997               0               0   \n",
       "9998               0               0   \n",
       "9999               1               1   \n",
       "\n",
       "                                              tokenized  tokens_num  \\\n",
       "0     [stuff, going, moment, mj, started, listening,...         167   \n",
       "1     [classic, war, worlds, timothy, hines, enterta...          67   \n",
       "2     [film, starts, manager, nicholas, bell, giving...         217   \n",
       "3     [must, assumed, praised, film, greatest, filme...         164   \n",
       "4     [superbly, trashy, wondrously, unpretentious, ...         194   \n",
       "...                                                 ...         ...   \n",
       "9995  [actually, saw, movie, theater, soon, handed, ...          45   \n",
       "9996  [quite, get, rating, amati, girls, think, real...          72   \n",
       "9997  [contains, spoilers, movie, cheesy, 80s, horro...         206   \n",
       "9998  [hmm, hip, hop, music, period, western, modern...          73   \n",
       "9999  [clark, gable, plays, con, man, busts, life, h...          91   \n",
       "\n",
       "                                                 ngrams  \n",
       "0     [(stuff, going, moment), (going, moment, mj), ...  \n",
       "1     [(classic, war, worlds), (war, worlds, timothy...  \n",
       "2     [(film, starts, manager), (starts, manager, ni...  \n",
       "3     [(must, assumed, praised), (assumed, praised, ...  \n",
       "4     [(superbly, trashy, wondrously), (trashy, wond...  \n",
       "...                                                 ...  \n",
       "9995  [(actually, saw, movie), (saw, movie, theater)...  \n",
       "9996  [(quite, get, rating), (get, rating, amati), (...  \n",
       "9997  [(contains, spoilers, movie), (spoilers, movie...  \n",
       "9998  [(hmm, hip, hop), (hip, hop, music), (hop, mus...  \n",
       "9999  [(clark, gable, plays), (gable, plays, con), (...  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v40vn07jhs5r",
    "outputId": "c68c12aa-3322-4b15-d491-bf592642333e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7P1YvbYipQv",
    "outputId": "fe6b1a40-4299-414c-9a22-6b743db54707"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('movie', 'ever', 'seen')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "for _, row in data.iterrows():\n",
    "    for gram in row['ngrams']:\n",
    "        cnt[gram] += 1\n",
    "\n",
    "max(cnt, key=cnt.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>unique</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokens_num</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "      <td>167</td>\n",
       "      <td>[(stuff, going, moment), (going, moment, mj), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds\" by timothy hine...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[classic, war, worlds, timothy, hines, enterta...</td>\n",
       "      <td>67</td>\n",
       "      <td>[(classic, war, worlds), (war, worlds, timothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager (nicholas bell)...</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[film, starts, manager, nicholas, bell, giving...</td>\n",
       "      <td>217</td>\n",
       "      <td>[(film, starts, manager), (starts, manager, ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[must, assumed, praised, film, greatest, filme...</td>\n",
       "      <td>164</td>\n",
       "      <td>[(must, assumed, praised), (assumed, praised, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "      <td>194</td>\n",
       "      <td>[(superbly, trashy, wondrously), (trashy, wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>I actually saw this movie at a theater. As soo...</td>\n",
       "      <td>i actually saw this movie at a theater. as soo...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[actually, saw, movie, theater, soon, handed, ...</td>\n",
       "      <td>45</td>\n",
       "      <td>[(actually, saw, movie), (saw, movie, theater)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't quite get the rating for The Amati Gir...</td>\n",
       "      <td>i don't quite get the rating for the amati gir...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[quite, get, rating, amati, girls, think, real...</td>\n",
       "      <td>72</td>\n",
       "      <td>[(quite, get, rating), (get, rating, amati), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>*Contains some spoilers* This movie is cheesy ...</td>\n",
       "      <td>*contains some spoilers* this movie is cheesy ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[contains, spoilers, movie, cheesy, 80s, horro...</td>\n",
       "      <td>206</td>\n",
       "      <td>[(contains, spoilers, movie), (spoilers, movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>Hmm, Hip Hop music to a period western. Modern...</td>\n",
       "      <td>hmm, hip hop music to a period western. modern...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hmm, hip, hop, music, period, western, modern...</td>\n",
       "      <td>73</td>\n",
       "      <td>[(hmm, hip, hop), (hip, hop, music), (hop, mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>clark gable plays a con man who busts into the...</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[clark, gable, plays, con, man, busts, life, h...</td>\n",
       "      <td>91</td>\n",
       "      <td>[(clark, gable, plays), (gable, plays, con), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review  \\\n",
       "0             1  With all this stuff going down at the moment w...   \n",
       "1             1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2             0  The film starts with a manager (Nicholas Bell)...   \n",
       "3             0  It must be assumed that those who praised this...   \n",
       "4             1  Superbly trashy and wondrously unpretentious 8...   \n",
       "...         ...                                                ...   \n",
       "9995          0  I actually saw this movie at a theater. As soo...   \n",
       "9996          0  I don't quite get the rating for The Amati Gir...   \n",
       "9997          0  *Contains some spoilers* This movie is cheesy ...   \n",
       "9998          0  Hmm, Hip Hop music to a period western. Modern...   \n",
       "9999          1  Clark Gable plays a con man who busts into the...   \n",
       "\n",
       "                                         cleaned_review  unique  \\\n",
       "0     with all this stuff going down at the moment w...      36   \n",
       "1     the classic war of the worlds\" by timothy hine...      29   \n",
       "2     the film starts with a manager (nicholas bell)...      39   \n",
       "3     it must be assumed that those who praised this...      39   \n",
       "4     superbly trashy and wondrously unpretentious 8...      41   \n",
       "...                                                 ...     ...   \n",
       "9995  i actually saw this movie at a theater. as soo...      31   \n",
       "9996  i don't quite get the rating for the amati gir...      36   \n",
       "9997  *contains some spoilers* this movie is cheesy ...      39   \n",
       "9998  hmm, hip hop music to a period western. modern...      30   \n",
       "9999  clark gable plays a con man who busts into the...      33   \n",
       "\n",
       "      positive_count  negative_count  \\\n",
       "0                  1               1   \n",
       "1                  0               0   \n",
       "2                  8               8   \n",
       "3                  3               3   \n",
       "4                  1               1   \n",
       "...              ...             ...   \n",
       "9995               0               0   \n",
       "9996               0               0   \n",
       "9997               0               0   \n",
       "9998               0               0   \n",
       "9999               1               1   \n",
       "\n",
       "                                              tokenized  tokens_num  \\\n",
       "0     [stuff, going, moment, mj, started, listening,...         167   \n",
       "1     [classic, war, worlds, timothy, hines, enterta...          67   \n",
       "2     [film, starts, manager, nicholas, bell, giving...         217   \n",
       "3     [must, assumed, praised, film, greatest, filme...         164   \n",
       "4     [superbly, trashy, wondrously, unpretentious, ...         194   \n",
       "...                                                 ...         ...   \n",
       "9995  [actually, saw, movie, theater, soon, handed, ...          45   \n",
       "9996  [quite, get, rating, amati, girls, think, real...          72   \n",
       "9997  [contains, spoilers, movie, cheesy, 80s, horro...         206   \n",
       "9998  [hmm, hip, hop, music, period, western, modern...          73   \n",
       "9999  [clark, gable, plays, con, man, busts, life, h...          91   \n",
       "\n",
       "                                                 ngrams  \n",
       "0     [(stuff, going, moment), (going, moment, mj), ...  \n",
       "1     [(classic, war, worlds), (war, worlds, timothy...  \n",
       "2     [(film, starts, manager), (starts, manager, ni...  \n",
       "3     [(must, assumed, praised), (assumed, praised, ...  \n",
       "4     [(superbly, trashy, wondrously), (trashy, wond...  \n",
       "...                                                 ...  \n",
       "9995  [(actually, saw, movie), (saw, movie, theater)...  \n",
       "9996  [(quite, get, rating), (get, rating, amati), (...  \n",
       "9997  [(contains, spoilers, movie), (spoilers, movie...  \n",
       "9998  [(hmm, hip, hop), (hip, hop, music), (hop, mus...  \n",
       "9999  [(clark, gable, plays), (gable, plays, con), (...  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lXirF0uJPHb"
   },
   "source": [
    "**Task 6 (1 point)**\n",
    "Use `WordPunctTokenizer` from `nltk` library for text tokenization. Apply it to `data['cleaned_review']`, then remove punctuation using `string.punctuation` and stopwords as before.\n",
    "\n",
    "What is top-10 most frequent tokens? (Write tokens in one string separated by spaces).\n",
    "\n",
    "**Example answer:** `'mother film cinema two good film even would really story'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "cLtZbQeeJPHb"
   },
   "outputs": [],
   "source": [
    "from nltk import WordPunctTokenizer\n",
    "import string\n",
    "\n",
    "tk = WordPunctTokenizer()\n",
    "\n",
    "data['nltk_tokenized'] = data['cleaned_review'].apply(lambda x: tk.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_and_stopwords(words):\n",
    "    words_copy = list(words)\n",
    "    for word in words_copy:\n",
    "        if word in STOPWORDS:\n",
    "            words.remove(word)\n",
    "    \n",
    "        for i in word:\n",
    "            if i in string.punctuation or i=='¨':                \n",
    "                words.remove(word)\n",
    "                break\n",
    "    return(words)\n",
    "data['nltk_tokenized'] = data['nltk_tokenized'].apply(remove_punct_and_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "B6j9nu6wJPHc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 17578),\n",
       " ('film', 16532),\n",
       " ('one', 10624),\n",
       " ('like', 8224),\n",
       " ('good', 6124),\n",
       " ('time', 5119),\n",
       " ('even', 5076),\n",
       " ('would', 4938),\n",
       " ('really', 4714),\n",
       " ('story', 4679)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "for _,row in data.iterrows():\n",
    "    cnt.update(row['nltk_tokenized'])\n",
    "    \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct_and_stopwords(words):\n",
    "    words_copy = list(words)\n",
    "    for word in words_copy:\n",
    "        if word in STOPWORDS:\n",
    "            words.remove(word)\n",
    "    \n",
    "        for i in word:\n",
    "            if i in string.punctuation or i=='¨':                \n",
    "                words.remove(word)\n",
    "                break\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jurassik', 'scientist', 'park']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct_and_stopwords(['¨', 'jurassik', 'scientist', 'park', '.', ').'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shvFs1B8JPHc"
   },
   "source": [
    "**Task 7 (1 point)** Using `SnowballStemmer ` from `nltk.stem.snowball` stem first 100 lines in the data (`data.head(100)['nltk_tokenized']`). \n",
    "\n",
    "What is the number of unique stems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_100 = data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "_Ud1b2PyJPHc"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "SNRDfO1ZJPHc"
   },
   "outputs": [],
   "source": [
    "stem_words = []\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "for _, row in data_100.iterrows():\n",
    "    for word in row['nltk_tokenized']:\n",
    "        x = snow_stemmer.stem(word)\n",
    "        stem_words.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3452"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(stem_words))\n",
    "# stem_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MFGEuDzJPHd"
   },
   "source": [
    "**Task 8 (1 point)** Using `nltk.stem.WordNetLemmatizer()` lemmatize first 100 lines in the data (`data.head(100)['nltk_tokenized']`). \n",
    "\n",
    "What is the number of unique lemmas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "a2F_mWDNJPHd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/riya/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemm_words = []\n",
    "for _, row in data_100.iterrows():\n",
    "    for word in row['nltk_tokenized']:\n",
    "        x = lemmatizer.lemmatize(word)\n",
    "        lemm_words.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "ZH6dwexsJPHd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4040"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lemm_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB2VpUzrJPHd"
   },
   "source": [
    "### Classification model\n",
    "\n",
    "Now it's time to solve a text classification task. First, split the data using the cell below (do not change the random state!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "mRZ6UHkEJPHd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>unique</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokens_num</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>nltk_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>0</td>\n",
       "      <td>Actress Patty Duke wrote an insightful, funny,...</td>\n",
       "      <td>actress patty duke wrote an insightful, funny,...</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[actress, patty, duke, wrote, insightful, funn...</td>\n",
       "      <td>94</td>\n",
       "      <td>[(actress, patty, duke), (patty, duke, wrote),...</td>\n",
       "      <td>[actress, patty, duke, wrote, insightful, funn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1</td>\n",
       "      <td>In answer to the person who made the comment a...</td>\n",
       "      <td>in answer to the person who made the comment a...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[answer, person, made, comment, film, drags, b...</td>\n",
       "      <td>57</td>\n",
       "      <td>[(answer, person, made), (person, made, commen...</td>\n",
       "      <td>[answer, person, made, comment, film, drags, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0</td>\n",
       "      <td>Madison is not too bad-if you like simplistic...</td>\n",
       "      <td>madison is not too bad-if you like simplistic...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[madison, bad, like, simplistic, non, offensiv...</td>\n",
       "      <td>185</td>\n",
       "      <td>[(madison, bad, like), (bad, like, simplistic)...</td>\n",
       "      <td>[madison, bad, like, simplistic, non, offensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a strange sex comedy because there`s v...</td>\n",
       "      <td>this is a strange sex comedy because there`s v...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[strange, sex, comedy, little, comedy, whole, ...</td>\n",
       "      <td>60</td>\n",
       "      <td>[(strange, sex, comedy), (sex, comedy, little)...</td>\n",
       "      <td>[strange, sex, comedy, little, comedy, whole, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>1</td>\n",
       "      <td>Thats My Bush is first of all a very entertain...</td>\n",
       "      <td>thats my bush is first of all a very entertain...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[thats, bush, first, entertaining, show, parke...</td>\n",
       "      <td>178</td>\n",
       "      <td>[(thats, bush, first), (bush, first, entertain...</td>\n",
       "      <td>[thats, bush, first, entertaining, show, parke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             review  \\\n",
       "9254          0  Actress Patty Duke wrote an insightful, funny,...   \n",
       "1561          1  In answer to the person who made the comment a...   \n",
       "1670          0  Madison is not too bad-if you like simplistic...   \n",
       "6087          0  This is a strange sex comedy because there`s v...   \n",
       "6669          1  Thats My Bush is first of all a very entertain...   \n",
       "\n",
       "                                         cleaned_review  unique  \\\n",
       "9254  actress patty duke wrote an insightful, funny,...      33   \n",
       "1561  in answer to the person who made the comment a...      31   \n",
       "1670  madison is not too bad-if you like simplistic...      42   \n",
       "6087  this is a strange sex comedy because there`s v...      30   \n",
       "6669  thats my bush is first of all a very entertain...      35   \n",
       "\n",
       "      positive_count  negative_count  \\\n",
       "9254               3               3   \n",
       "1561               0               0   \n",
       "1670               2               2   \n",
       "6087               0               0   \n",
       "6669               0               0   \n",
       "\n",
       "                                              tokenized  tokens_num  \\\n",
       "9254  [actress, patty, duke, wrote, insightful, funn...          94   \n",
       "1561  [answer, person, made, comment, film, drags, b...          57   \n",
       "1670  [madison, bad, like, simplistic, non, offensiv...         185   \n",
       "6087  [strange, sex, comedy, little, comedy, whole, ...          60   \n",
       "6669  [thats, bush, first, entertaining, show, parke...         178   \n",
       "\n",
       "                                                 ngrams  \\\n",
       "9254  [(actress, patty, duke), (patty, duke, wrote),...   \n",
       "1561  [(answer, person, made), (person, made, commen...   \n",
       "1670  [(madison, bad, like), (bad, like, simplistic)...   \n",
       "6087  [(strange, sex, comedy), (sex, comedy, little)...   \n",
       "6669  [(thats, bush, first), (bush, first, entertain...   \n",
       "\n",
       "                                         nltk_tokenized  \n",
       "9254  [actress, patty, duke, wrote, insightful, funn...  \n",
       "1561  [answer, person, made, comment, film, drags, b...  \n",
       "1670  [madison, bad, like, simplistic, non, offensiv...  \n",
       "6087  [strange, sex, comedy, little, comedy, whole, ...  \n",
       "6669  [thats, bush, first, entertaining, show, parke...  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, test_size = 0.2, random_state = 42)\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycJBPJqCJPHe"
   },
   "source": [
    "Compute features for `train_df` and `test_df`.\n",
    "* length of the original review\n",
    "* length of the text in tokens (use `nltk_tokenized` column)\n",
    "* length of the text in 3-grams (use `3gram` column)\n",
    "* number of unigue tokens (use `nltk_tokenized` column)\n",
    "* number of unique 3-grams (use `3gram` column)\n",
    "* positive_count and negative_count from task 3\n",
    "* counters for tokens best, worst, good, bad, excellent, horrible (use `nltk_tokenized` column and create a separate feature for each of this tokens).\n",
    "\n",
    "Thus, you obtain the following list of features: \n",
    "\n",
    "`features = ['original_length','token_length', '3gram_length', 'token_count', '3gram_count', 'best_count', 'worst_count', 'good_count', 'bad_count', 'excellent_count', 'horrible_count', 'positive_count', 'negative_count']`\n",
    "\n",
    "\n",
    "**Task 9 (1 point)** \n",
    "\n",
    "Compute **absolute** correlation between features and target variable `sentiment` in `train_df`. What is the most correlated variable?\n",
    "\n",
    "**Hint:** use `np.corrcoef` and do not forget about `abs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['original_length'] = train_df['review'].apply(lambda x: len(x))\n",
    "test_df['original_length'] = test_df['review'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['token_length'] = train_df['nltk_tokenized'].apply(lambda x: len(x))\n",
    "test_df['token_length'] = test_df['nltk_tokenized'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['3gram_length'] = train_df['ngrams'].apply(lambda x: len(x))\n",
    "test_df['3gram_length'] = test_df['ngrams'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['token_count'] = train_df['nltk_tokenized'].apply(lambda x: len(set(x)))\n",
    "test_df['token_count'] = test_df['nltk_tokenized'].apply(lambda x: len(set(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['3gram_count'] = train_df['ngrams'].apply(lambda x: len(set(x)))\n",
    "test_df['3gram_count'] = test_df['ngrams'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['best_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('best'))\n",
    "test_df['best_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('best'))\n",
    "train_df['worst_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('worst'))\n",
    "test_df['worst_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('worst'))\n",
    "train_df['good_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('good'))\n",
    "test_df['good_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('good'))\n",
    "train_df['bad_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('bad'))\n",
    "test_df['bad_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('bad'))\n",
    "train_df['excellent_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('excellent'))\n",
    "test_df['excellent_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('excellent'))\n",
    "train_df['horrible_count'] = train_df['nltk_tokenized'].apply(lambda x: x.count('horrible'))\n",
    "test_df['horrible_count'] = test_df['nltk_tokenized'].apply(lambda x: x.count('horrible'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "GQeEVxqMJPHe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef for original_length is 0.01631844812397978\n",
      "Coef for token_length is 0.020055787050218564\n",
      "Coef for 3gram_length is 0.019990809298198114\n",
      "Coef for token_count is 0.015035220142316506\n",
      "Coef for 3gram_count is 0.020045209951380795\n",
      "Coef for best_count is 0.15141741713861748\n",
      "Coef for worst_count is 0.23431738493553936\n",
      "Coef for good_count is 0.020572444958314673\n",
      "Coef for bad_count is 0.2719072277745534\n",
      "Coef for excellent_count is 0.1544400755955548\n",
      "Coef for horrible_count is 0.1466411880678859\n",
      "Coef for positive_count is 0.03724083117531796\n",
      "Coef for negative_count is 0.04300851753180165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/zp8k8qn11yj_zf4pwq6kftsw0000gn/T/ipykernel_3515/510703226.py:1: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr   \n",
    "features = ['original_length','token_length', '3gram_length', 'token_count', '3gram_count', 'best_count', 'worst_count', 'good_count', 'bad_count', 'excellent_count', 'horrible_count', 'positive_count', 'negative_count']\n",
    "\n",
    "for feature in features:\n",
    "    coef = np.corrcoef(train_df[feature], train_df['sentiment'])\n",
    "    print(f'Coef for {feature} is {abs(coef)[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Jz-rqmVJPHe"
   },
   "outputs": [],
   "source": [
    "# q9 = ### YOUR SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9lO9HMDJPHe"
   },
   "source": [
    "**Task 10 (1 point)**\n",
    "\n",
    "Scale the data using `StandardScaler` from `sklearn` and train `LogisticRegression` with default parametes from `sklearn.linear_model`.\n",
    "\n",
    "What is F1-score for the `test_df`? Round your answer up to 4 points after the decimal point (`round(score, 4)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "Em4VoEoxJPHe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.9118237 ,  1.52612939,  1.52815924, ..., -0.18984995,\n",
       "         1.11983195,  1.15334776],\n",
       "       [ 0.22713586,  0.29786717,  0.29872198, ..., -0.18984995,\n",
       "         1.56234396,  1.60325911],\n",
       "       [ 1.19179545,  1.15656376,  1.15824006, ..., -0.18984995,\n",
       "         0.23480793,  0.25352505],\n",
       "       ...,\n",
       "       [-0.91777839, -0.95213419, -0.95247524, ..., -0.18984995,\n",
       "        -0.65021608, -0.64629766],\n",
       "       [ 0.98083806,  1.08047673,  1.08208023, ..., -0.18984995,\n",
       "         1.11983195,  1.15334776],\n",
       "       [-0.76030316, -0.69126434, -0.69135582, ..., -0.18984995,\n",
       "        -0.65021608, -0.64629766]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[features])\n",
    "scaler.transform(train_df[features])\n",
    "scaler.transform(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(train_df[features], train_df['sentiment'])\n",
    "y_pred = clf.predict(test_df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "b0WcdBdKTMyFnHQXStzMGA"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
